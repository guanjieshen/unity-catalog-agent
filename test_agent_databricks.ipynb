{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Unity Catalog Data Advisor Agent - Test Notebook\n",
        "\n",
        "This notebook tests the Unity Catalog Data Advisor Agent with Peloton data queries.\n",
        "\n",
        "## Setup\n",
        "1. Upload all project files to your Databricks workspace\n",
        "2. Make sure `config.py` has your `LLM_ENDPOINT_NAME` and `VECTOR_SEARCH_INDEX_NAME` configured\n",
        "3. Run the cells below to test the agent\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install -U -qqqq backoff databricks-openai uv databricks-agents mlflow-skinny[databricks]\n",
        "dbutils.library.restartPython()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Enable MLflow OpenAI autologging before importing the agent\n",
        "import mlflow\n",
        "mlflow.openai.autolog()\n",
        "\n",
        "# Import the agent\n",
        "from agent import AGENT\n",
        "from mlflow.types.responses import ResponsesAgentRequest\n",
        "\n",
        "print(\"Agent loaded successfully!\")\n",
        "print(f\"LLM Endpoint: {AGENT.llm_endpoint}\")\n",
        "print(f\"Available tools: {list(AGENT._tools_dict.keys())}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test 1: Peloton Data Discovery Query\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test query about Peloton data\n",
        "request = ResponsesAgentRequest(\n",
        "    input=[{\n",
        "        \"role\": \"user\", \n",
        "        \"content\": \"What Peloton data do we have available? I need to analyze Peloton customer behavior and usage patterns.\"\n",
        "    }],\n",
        "    custom_inputs={\"session_id\": \"peloton-test-session\"}\n",
        ")\n",
        "\n",
        "print(\"Query: What Peloton data do we have available?\")\n",
        "print(\"=\" * 80)\n",
        "print()\n",
        "\n",
        "response = AGENT.predict(request)\n",
        "\n",
        "# Print the response in a readable format\n",
        "for output in response.output:\n",
        "    if hasattr(output, 'content'):\n",
        "        print(output.content)\n",
        "    elif isinstance(output, dict) and 'content' in output:\n",
        "        print(output['content'])\n",
        "    else:\n",
        "        print(output)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test 2: Streaming Response\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test streaming response\n",
        "request = ResponsesAgentRequest(\n",
        "    input=[{\n",
        "        \"role\": \"user\", \n",
        "        \"content\": \"What tables contain Peloton sales or transaction data?\"\n",
        "    }],\n",
        "    custom_inputs={\"session_id\": \"streaming-test-session\"}\n",
        ")\n",
        "\n",
        "print(\"Query: What tables contain Peloton sales or transaction data?\")\n",
        "print(\"=\" * 80)\n",
        "print()\n",
        "\n",
        "for chunk in AGENT.predict_stream(request):\n",
        "    chunk_data = chunk.model_dump(exclude_none=True)\n",
        "    if chunk_data.get(\"type\") == \"response.output_item.done\":\n",
        "        item = chunk_data.get(\"item\", {})\n",
        "        if item.get(\"type\") == \"text\":\n",
        "            print(item.get(\"content\", \"\"), end=\"\", flush=True)\n",
        "        elif item.get(\"type\") == \"function_call_output\":\n",
        "            print(f\"\\n[Tool Output]: {item.get('content', '')}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test 3: Custom Query\n",
        "\n",
        "Modify the query below to test your own data discovery questions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Custom query - modify as needed\n",
        "custom_query = \"What datasets are available for analyzing customer engagement?\"\n",
        "\n",
        "request = ResponsesAgentRequest(\n",
        "    input=[{\"role\": \"user\", \"content\": custom_query}],\n",
        "    custom_inputs={\"session_id\": \"custom-query-session\"}\n",
        ")\n",
        "\n",
        "print(f\"Query: {custom_query}\")\n",
        "print(\"=\" * 80)\n",
        "print()\n",
        "\n",
        "response = AGENT.predict(request)\n",
        "\n",
        "for output in response.output:\n",
        "    if hasattr(output, 'content'):\n",
        "        print(output.content)\n",
        "    elif isinstance(output, dict) and 'content' in output:\n",
        "        print(output['content'])\n",
        "    else:\n",
        "        print(output)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Troubleshooting\n",
        "\n",
        "If you encounter errors:\n",
        "\n",
        "1. **Check configuration**: Verify `LLM_ENDPOINT_NAME` and `VECTOR_SEARCH_INDEX_NAME` in `config.py`\n",
        "2. **Check permissions**: Ensure you have access to:\n",
        "   - The model serving endpoint\n",
        "   - The vector search index\n",
        "   - Unity Catalog functions (system.ai.python_exec)\n",
        "3. **Check MLflow traces**: View traces in the MLflow UI to see tool calls and LLM interactions\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
